{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction des données brut, ajout des informations de geojson et enregistrement en parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from geoalchemy2 import Geometry\n",
    "import psycopg2\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Importation des données, descriptif et adaptation des types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1= '../data_brut/taxi_trip_2016-01.csv'\n",
    "path2= '../data_brut/taxi_trip_2016-02.csv'\n",
    "path3= '../data_brut/taxi_trip_2016-03.csv'\n",
    "\n",
    "# Load data\n",
    "data1 = pd.read_csv(path1)\n",
    "data2 = pd.read_csv(path2)\n",
    "data3 = pd.read_csv(path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge des 3 df\n",
    "data = pd.concat([data1, data2, data3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data1, data2, data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "VendorID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tpep_pickup_datetime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tpep_dropoff_datetime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "passenger_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trip_distance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pickup_longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pickup_latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RatecodeID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "store_and_fwd_flag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dropoff_longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dropoff_latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "payment_type",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fare_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mta_tax",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tip_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tolls_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "improvement_surcharge",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_amount",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e608da77-72a4-4958-b5c6-fc723262627e",
       "rows": [
        [
         "0",
         "2",
         "2016-01-01 00:00:00",
         "2016-01-01 00:00:00",
         "2",
         "1.1",
         "-73.99037170410156",
         "40.73469543457031",
         "1",
         "N",
         "-73.98184204101561",
         "40.73240661621094",
         "2",
         "7.5",
         "0.5",
         "0.5",
         "0.0",
         "0.0",
         "0.3",
         "8.8"
        ],
        [
         "1",
         "2",
         "2016-01-01 00:00:00",
         "2016-01-01 00:00:00",
         "5",
         "4.9",
         "-73.98078155517578",
         "40.72991180419922",
         "1",
         "N",
         "-73.94447326660156",
         "40.716678619384766",
         "1",
         "18.0",
         "0.5",
         "0.5",
         "0.0",
         "0.0",
         "0.3",
         "19.3"
        ],
        [
         "2",
         "2",
         "2016-01-01 00:00:00",
         "2016-01-01 00:00:00",
         "1",
         "10.54",
         "-73.98455047607422",
         "40.6795654296875",
         "1",
         "N",
         "-73.95027160644531",
         "40.78892517089844",
         "1",
         "33.0",
         "0.5",
         "0.5",
         "0.0",
         "0.0",
         "0.3",
         "34.3"
        ],
        [
         "3",
         "2",
         "2016-01-01 00:00:00",
         "2016-01-01 00:00:00",
         "1",
         "4.75",
         "-73.99346923828125",
         "40.71899032592773",
         "1",
         "N",
         "-73.96224212646483",
         "40.65733337402344",
         "2",
         "16.5",
         "0.0",
         "0.5",
         "0.0",
         "0.0",
         "0.3",
         "17.3"
        ],
        [
         "4",
         "2",
         "2016-01-01 00:00:00",
         "2016-01-01 00:00:00",
         "3",
         "1.76",
         "-73.96062469482422",
         "40.78133010864258",
         "1",
         "N",
         "-73.97726440429686",
         "40.75851440429688",
         "2",
         "8.0",
         "0.0",
         "0.5",
         "0.0",
         "0.0",
         "0.3",
         "8.8"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-73.990372</td>\n",
       "      <td>40.734695</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.981842</td>\n",
       "      <td>40.732407</td>\n",
       "      <td>2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>4.90</td>\n",
       "      <td>-73.980782</td>\n",
       "      <td>40.729912</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.944473</td>\n",
       "      <td>40.716679</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>10.54</td>\n",
       "      <td>-73.984550</td>\n",
       "      <td>40.679565</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.950272</td>\n",
       "      <td>40.788925</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>34.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.75</td>\n",
       "      <td>-73.993469</td>\n",
       "      <td>40.718990</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.962242</td>\n",
       "      <td>40.657333</td>\n",
       "      <td>2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1.76</td>\n",
       "      <td>-73.960625</td>\n",
       "      <td>40.781330</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.977264</td>\n",
       "      <td>40.758514</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2016-01-01 00:00:00   2016-01-01 00:00:00                2   \n",
       "1         2  2016-01-01 00:00:00   2016-01-01 00:00:00                5   \n",
       "2         2  2016-01-01 00:00:00   2016-01-01 00:00:00                1   \n",
       "3         2  2016-01-01 00:00:00   2016-01-01 00:00:00                1   \n",
       "4         2  2016-01-01 00:00:00   2016-01-01 00:00:00                3   \n",
       "\n",
       "   trip_distance  pickup_longitude  pickup_latitude  RatecodeID  \\\n",
       "0           1.10        -73.990372        40.734695           1   \n",
       "1           4.90        -73.980782        40.729912           1   \n",
       "2          10.54        -73.984550        40.679565           1   \n",
       "3           4.75        -73.993469        40.718990           1   \n",
       "4           1.76        -73.960625        40.781330           1   \n",
       "\n",
       "  store_and_fwd_flag  dropoff_longitude  dropoff_latitude  payment_type  \\\n",
       "0                  N         -73.981842         40.732407             2   \n",
       "1                  N         -73.944473         40.716679             1   \n",
       "2                  N         -73.950272         40.788925             1   \n",
       "3                  N         -73.962242         40.657333             2   \n",
       "4                  N         -73.977264         40.758514             2   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0          7.5    0.5      0.5         0.0           0.0   \n",
       "1         18.0    0.5      0.5         0.0           0.0   \n",
       "2         33.0    0.5      0.5         0.0           0.0   \n",
       "3         16.5    0.0      0.5         0.0           0.0   \n",
       "4          8.0    0.0      0.5         0.0           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  \n",
       "0                    0.3           8.8  \n",
       "1                    0.3          19.3  \n",
       "2                    0.3          34.3  \n",
       "3                    0.3          17.3  \n",
       "4                    0.3           8.8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34499859, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tpep_pickup_datetime'] = pd.to_datetime(data['tpep_pickup_datetime'])\n",
    "data['tpep_dropoff_datetime'] = pd.to_datetime(data['tpep_dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                         34499859\n",
       "mean     2016-02-16 16:28:47.850749696\n",
       "min                2016-01-01 00:00:00\n",
       "25%                2016-01-25 23:54:45\n",
       "50%                2016-02-17 11:37:35\n",
       "75%         2016-03-10 00:04:20.500000\n",
       "max                2016-03-31 23:59:59\n",
       "Name: tpep_pickup_datetime, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tpep_pickup_datetime'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                         34499859\n",
       "mean     2016-02-16 16:44:17.778065152\n",
       "min                2015-02-07 15:35:25\n",
       "25%         2016-01-26 00:11:38.500000\n",
       "50%                2016-02-17 11:54:02\n",
       "75%                2016-03-10 00:18:53\n",
       "max                2016-06-29 15:58:16\n",
       "Name: tpep_dropoff_datetime, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tpep_dropoff_datetime'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34499856, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - AJout des information de quartier et arrondissment de new york depuis le geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration PostgreSQL\n",
    "\n",
    "# Charger les variables d'environnement depuis le fichier .env\n",
    "load_dotenv()\n",
    "\n",
    "# Récupérer les valeurs des variables\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "\n",
    "# Connexion PostgreSQL\n",
    "engine = create_engine(f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 1 : Création de la base de données et activation de PostGIS\n",
    "def setup_database():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD, host=DB_HOST, port=DB_PORT\n",
    "        )\n",
    "        conn.autocommit = True  # Permet d'exécuter des commandes DDL\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Activer PostGIS\n",
    "        cursor.execute(\"CREATE EXTENSION IF NOT EXISTS postgis;\")\n",
    "        cursor.execute(\"SELECT postgis_version();\")  # Vérifier si PostGIS est actif\n",
    "        \n",
    "        version = cursor.fetchone()\n",
    "        print(\"✅ PostGIS est actif, version :\", version[0]) # type: ignore\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(\"❌ Erreur lors de l'activation de PostGIS :\", e)\n",
    "\n",
    "setup_database()\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT postgis_version();\"))\n",
    "    postgis_version = result.scalar()\n",
    "    print(\"PostGIS est bien activé, version :\", postgis_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 2 : Charger le GeoJSON (Zones de NYC)\n",
    "geojson_path = \"data_geojson/custom-pedia-cities-nyc-Mar2018.geojson\"\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "# Vérifier les colonnes disponibles\n",
    "print(\"Colonnes du GeoJSON :\", gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 3 : Importer les zones dans PostgreSQL\n",
    "gdf.to_postgis(\"zones_nyc\", engine, if_exists=\"replace\", dtype={\"geometry\": Geometry(\"POLYGON\", srid=4326)}) # type: ignore\n",
    "print(\"Données des zones NYC importées dans PostgreSQL !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 4 : Chargement et conversion des coordonnées GPS en CSV\n",
    "csv_path = \"data_clean/points_taxis.csv\"\n",
    "\n",
    "data_cleaned['geometry_pickup'] = gpd.points_from_xy(data_cleaned['pickup_longitude'], data_cleaned['pickup_latitude'])\n",
    "data_cleaned['geometry_dropoff'] = gpd.points_from_xy(data_cleaned['dropoff_longitude'], data_cleaned['dropoff_latitude'])\n",
    "\n",
    "data_cleaned[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']].to_csv(csv_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Données GPS enregistrées en CSV pour `pickup` et `dropoff` \")\n",
    "\n",
    "\n",
    "print(\"Données GPS sauvegardées en CSV pour import rapide \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 5 : Suppression des index pour accélérer l'insertion\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"DROP INDEX IF EXISTS idx_points_geo;\"))\n",
    "    conn.execute(text(\"DROP INDEX IF EXISTS idx_zones_geo;\"))\n",
    "    print(\"Index supprimés temporairement pour accélérer l'insertion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 6 : Création de la table `points_taxis`\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        DROP TABLE IF EXISTS points_taxis;\n",
    "        CREATE TABLE points_taxis (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            pickup_longitude DOUBLE PRECISION,\n",
    "            pickup_latitude DOUBLE PRECISION,\n",
    "            dropoff_longitude DOUBLE PRECISION,\n",
    "            dropoff_latitude DOUBLE PRECISION,\n",
    "            geometry_pickup GEOMETRY(Point, 4326),\n",
    "            geometry_dropoff GEOMETRY(Point, 4326)\n",
    "        );\n",
    "    \"\"\"))\n",
    "    print(\"Table `points_taxis` créée !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 7 : Importer les données GPS via `COPY` (ultra-rapide)\n",
    "conn = engine.raw_connection()  # Ouvrir la connexion\n",
    "cursor = conn.cursor()\n",
    "\n",
    "try:\n",
    "    with open(csv_path, \"r\") as f:\n",
    "        cursor.copy_expert(\"COPY points_taxis(pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude) FROM STDIN WITH CSV HEADER DELIMITER ',';\", f)\n",
    "    conn.commit()\n",
    "    print(\"Données des taxis importées via `COPY` 🚀\")\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 8 : Ajouter les colonnes `geometry_pickup` et `geometry_dropoff`\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        UPDATE points_taxis\n",
    "        SET geometry_pickup = ST_SetSRID(ST_MakePoint(pickup_longitude, pickup_latitude), 4326),\n",
    "            geometry_dropoff = ST_SetSRID(ST_MakePoint(dropoff_longitude, dropoff_latitude), 4326);\n",
    "    \"\"\"))\n",
    "    print(\"Géométries `pickup` et `dropoff` ajoutées !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Étape 9 : Réactivation des index\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"CREATE INDEX IF NOT EXISTS idx_points_geo ON points_taxis USING GIST (geometry_pickup);\"))\n",
    "    conn.execute(text(\"CREATE INDEX IF NOT EXISTS idx_points_dropoff ON points_taxis USING GIST (geometry_dropoff);\"))\n",
    "    conn.execute(text(\"CREATE INDEX IF NOT EXISTS idx_zones_geo ON zones_nyc USING GIST (geometry);\"))\n",
    "print(\"Index recréés après insertion !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 10 : Jointure spatiale optimisée pour `pickup` et `dropoff`\n",
    "query = \"\"\"\n",
    "SELECT  p.*, \n",
    "        z_pickup.borough AS pickup_borough, \n",
    "        z_pickup.neighborhood AS pickup_neighborhood,\n",
    "        z_dropoff.borough AS dropoff_borough,\n",
    "        z_dropoff.neighborhood AS dropoff_neighborhood\n",
    "FROM points_taxis p\n",
    "LEFT JOIN zones_nyc z_pickup ON ST_Within(p.geometry_pickup, z_pickup.geometry)\n",
    "LEFT JOIN zones_nyc z_dropoff ON ST_Within(p.geometry_dropoff, z_dropoff.geometry);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PostGIS est actif, version : 3.5 USE_GEOS=1 USE_PROJ=1 USE_STATS=1\n",
      "✅ PostGIS est bien activé, version : 3.5 USE_GEOS=1 USE_PROJ=1 USE_STATS=1\n",
      "📌 Colonnes du GeoJSON : Index(['neighborhood', 'boroughCode', 'borough', 'X.id', 'geometry'], dtype='object')\n",
      "✅ Données des zones NYC importées dans PostgreSQL !\n",
      "✅ Données GPS enregistrées en CSV pour `pickup` et `dropoff` 🚀\n",
      "✅ Données GPS sauvegardées en CSV pour import rapide 🚀\n",
      "🚀 Index supprimés temporairement pour accélérer l'insertion\n",
      "✅ Table `points_taxis` créée !\n",
      "✅ Données des taxis importées via `COPY` 🚀\n",
      "✅ Géométries `pickup` et `dropoff` ajoutées !\n",
      "✅ Index recréés après insertion !\n",
      "✅ Jointure terminée avec `pickup` et `dropoff` !\n",
      "   pickup_latitude  pickup_longitude pickup_borough  dropoff_latitude  \\\n",
      "0        40.734695        -73.990372      Manhattan         40.732407   \n",
      "1        40.729912        -73.980782      Manhattan         40.716679   \n",
      "2        40.679565        -73.984550       Brooklyn         40.788925   \n",
      "3        40.718990        -73.993469      Manhattan         40.657333   \n",
      "4        40.781330        -73.960625      Manhattan         40.758514   \n",
      "\n",
      "   dropoff_longitude dropoff_borough pickup_neighborhood  \\\n",
      "0         -73.981842       Manhattan            Gramercy   \n",
      "1         -73.944473        Brooklyn        East Village   \n",
      "2         -73.950272       Manhattan             Gowanus   \n",
      "3         -73.962242        Brooklyn     Lower East Side   \n",
      "4         -73.977264       Manhattan        Central Park   \n",
      "\n",
      "        dropoff_neighborhood  \n",
      "0                   Gramercy  \n",
      "1               Williamsburg  \n",
      "2                East Harlem  \n",
      "3  Prospect-Lefferts Gardens  \n",
      "4                    Midtown  \n"
     ]
    }
   ],
   "source": [
    "# Étape 11 : Récupérer les résultats et ajouter aux données\n",
    "result = pd.read_sql(query, engine)\n",
    "data_cleaned['pickup_borough'] = result['pickup_borough']\n",
    "data_cleaned['pickup_neighborhood'] = result['pickup_neighborhood']\n",
    "data_cleaned['dropoff_borough'] = result['dropoff_borough']\n",
    "data_cleaned['dropoff_neighborhood'] = result['dropoff_neighborhood']\n",
    "\n",
    "print(\"Jointure terminée avec `pickup` et `dropoff` !\")\n",
    "print(data_cleaned[['pickup_latitude', 'pickup_longitude', 'pickup_borough', 'dropoff_latitude', 'dropoff_longitude', 'dropoff_borough', 'pickup_neighborhood', 'dropoff_neighborhood']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.drop(columns=['geometry_pickup', 'geometry_dropoff'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Enregistrelment en format parquert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier enregistré en Parquet avec succès ! 🚀\n"
     ]
    }
   ],
   "source": [
    "data_cleaned.to_parquet('data_clean/taxi_trip_2016-preclean.parquet', index=False)\n",
    "print(\"Fichier enregistré en Parquet avec succès !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
