{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction des donn√©es brut, ajout des informations de geojson et enregistrement en parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from geoalchemy2 import Geometry\n",
    "import psycopg2\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Importation des donn√©es, descriptif et adaptation des types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1= '../data_brut/taxi_trip_2016-01.csv'\n",
    "path2= '../data_brut/taxi_trip_2016-02.csv'\n",
    "path3= '../data_brut/taxi_trip_2016-03.csv'\n",
    "\n",
    "# Load data\n",
    "data1 = pd.read_csv(path1)\n",
    "data2 = pd.read_csv(path2)\n",
    "data3 = pd.read_csv(path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge des 3 df\n",
    "data = pd.concat([data1, data2, data3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data1, data2, data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "VendorID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tpep_pickup_datetime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tpep_dropoff_datetime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "passenger_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trip_distance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pickup_longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pickup_latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RatecodeID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "store_and_fwd_flag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dropoff_longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dropoff_latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "payment_type",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fare_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "extra",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mta_tax",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tip_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tolls_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "improvement_surcharge",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_amount",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e608da77-72a4-4958-b5c6-fc723262627e",
       "rows": [
        [
         "0",
         "2",
         "2016-01-01 00:00:00",
         "2016-01-01 00:00:00",
         "2",
         "1.1",
         "-73.99037170410156",
         "40.73469543457031",
         "1",
         "N",
         "-73.98184204101561",
         "40.73240661621094",
         "2",
         "7.5",
         "0.5",
         "0.5",
         "0.0",
         "0.0",
         "0.3",
         "8.8"
        ],
        [
         "1",
         "2",
         "2016-01-01 00:00:00",
         "2016-01-01 00:00:00",
         "5",
         "4.9",
         "-73.98078155517578",
         "40.72991180419922",
         "1",
         "N",
         "-73.94447326660156",
         "40.716678619384766",
         "1",
         "18.0",
         "0.5",
         "0.5",
         "0.0",
         "0.0",
         "0.3",
         "19.3"
        ],
        [
         "2",
         "2",
         "2016-01-01 00:00:00",
         "2016-01-01 00:00:00",
         "1",
         "10.54",
         "-73.98455047607422",
         "40.6795654296875",
         "1",
         "N",
         "-73.95027160644531",
         "40.78892517089844",
         "1",
         "33.0",
         "0.5",
         "0.5",
         "0.0",
         "0.0",
         "0.3",
         "34.3"
        ],
        [
         "3",
         "2",
         "2016-01-01 00:00:00",
         "2016-01-01 00:00:00",
         "1",
         "4.75",
         "-73.99346923828125",
         "40.71899032592773",
         "1",
         "N",
         "-73.96224212646483",
         "40.65733337402344",
         "2",
         "16.5",
         "0.0",
         "0.5",
         "0.0",
         "0.0",
         "0.3",
         "17.3"
        ],
        [
         "4",
         "2",
         "2016-01-01 00:00:00",
         "2016-01-01 00:00:00",
         "3",
         "1.76",
         "-73.96062469482422",
         "40.78133010864258",
         "1",
         "N",
         "-73.97726440429686",
         "40.75851440429688",
         "2",
         "8.0",
         "0.0",
         "0.5",
         "0.0",
         "0.0",
         "0.3",
         "8.8"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-73.990372</td>\n",
       "      <td>40.734695</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.981842</td>\n",
       "      <td>40.732407</td>\n",
       "      <td>2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>4.90</td>\n",
       "      <td>-73.980782</td>\n",
       "      <td>40.729912</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.944473</td>\n",
       "      <td>40.716679</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>10.54</td>\n",
       "      <td>-73.984550</td>\n",
       "      <td>40.679565</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.950272</td>\n",
       "      <td>40.788925</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>34.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.75</td>\n",
       "      <td>-73.993469</td>\n",
       "      <td>40.718990</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.962242</td>\n",
       "      <td>40.657333</td>\n",
       "      <td>2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1.76</td>\n",
       "      <td>-73.960625</td>\n",
       "      <td>40.781330</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.977264</td>\n",
       "      <td>40.758514</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2016-01-01 00:00:00   2016-01-01 00:00:00                2   \n",
       "1         2  2016-01-01 00:00:00   2016-01-01 00:00:00                5   \n",
       "2         2  2016-01-01 00:00:00   2016-01-01 00:00:00                1   \n",
       "3         2  2016-01-01 00:00:00   2016-01-01 00:00:00                1   \n",
       "4         2  2016-01-01 00:00:00   2016-01-01 00:00:00                3   \n",
       "\n",
       "   trip_distance  pickup_longitude  pickup_latitude  RatecodeID  \\\n",
       "0           1.10        -73.990372        40.734695           1   \n",
       "1           4.90        -73.980782        40.729912           1   \n",
       "2          10.54        -73.984550        40.679565           1   \n",
       "3           4.75        -73.993469        40.718990           1   \n",
       "4           1.76        -73.960625        40.781330           1   \n",
       "\n",
       "  store_and_fwd_flag  dropoff_longitude  dropoff_latitude  payment_type  \\\n",
       "0                  N         -73.981842         40.732407             2   \n",
       "1                  N         -73.944473         40.716679             1   \n",
       "2                  N         -73.950272         40.788925             1   \n",
       "3                  N         -73.962242         40.657333             2   \n",
       "4                  N         -73.977264         40.758514             2   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0          7.5    0.5      0.5         0.0           0.0   \n",
       "1         18.0    0.5      0.5         0.0           0.0   \n",
       "2         33.0    0.5      0.5         0.0           0.0   \n",
       "3         16.5    0.0      0.5         0.0           0.0   \n",
       "4          8.0    0.0      0.5         0.0           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  \n",
       "0                    0.3           8.8  \n",
       "1                    0.3          19.3  \n",
       "2                    0.3          34.3  \n",
       "3                    0.3          17.3  \n",
       "4                    0.3           8.8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34499859, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tpep_pickup_datetime'] = pd.to_datetime(data['tpep_pickup_datetime'])\n",
    "data['tpep_dropoff_datetime'] = pd.to_datetime(data['tpep_dropoff_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                         34499859\n",
       "mean     2016-02-16 16:28:47.850749696\n",
       "min                2016-01-01 00:00:00\n",
       "25%                2016-01-25 23:54:45\n",
       "50%                2016-02-17 11:37:35\n",
       "75%         2016-03-10 00:04:20.500000\n",
       "max                2016-03-31 23:59:59\n",
       "Name: tpep_pickup_datetime, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tpep_pickup_datetime'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                         34499859\n",
       "mean     2016-02-16 16:44:17.778065152\n",
       "min                2015-02-07 15:35:25\n",
       "25%         2016-01-26 00:11:38.500000\n",
       "50%                2016-02-17 11:54:02\n",
       "75%                2016-03-10 00:18:53\n",
       "max                2016-06-29 15:58:16\n",
       "Name: tpep_dropoff_datetime, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tpep_dropoff_datetime'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34499856, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - AJout des information de quartier et arrondissment de new york depuis le geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration PostgreSQL\n",
    "\n",
    "# Charger les variables d'environnement depuis le fichier .env\n",
    "load_dotenv()\n",
    "\n",
    "# R√©cup√©rer les valeurs des variables\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "\n",
    "# Connexion PostgreSQL\n",
    "engine = create_engine(f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 1 : Cr√©ation de la base de donn√©es et activation de PostGIS\n",
    "def setup_database():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD, host=DB_HOST, port=DB_PORT\n",
    "        )\n",
    "        conn.autocommit = True  # Permet d'ex√©cuter des commandes DDL\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Activer PostGIS\n",
    "        cursor.execute(\"CREATE EXTENSION IF NOT EXISTS postgis;\")\n",
    "        cursor.execute(\"SELECT postgis_version();\")  # V√©rifier si PostGIS est actif\n",
    "        \n",
    "        version = cursor.fetchone()\n",
    "        print(\"‚úÖ PostGIS est actif, version :\", version[0]) # type: ignore\n",
    "        \n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Erreur lors de l'activation de PostGIS :\", e)\n",
    "\n",
    "setup_database()\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT postgis_version();\"))\n",
    "    postgis_version = result.scalar()\n",
    "    print(\"PostGIS est bien activ√©, version :\", postgis_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 2 : Charger le GeoJSON (Zones de NYC)\n",
    "geojson_path = \"data_geojson/custom-pedia-cities-nyc-Mar2018.geojson\"\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "# V√©rifier les colonnes disponibles\n",
    "print(\"Colonnes du GeoJSON :\", gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 3 : Importer les zones dans PostgreSQL\n",
    "gdf.to_postgis(\"zones_nyc\", engine, if_exists=\"replace\", dtype={\"geometry\": Geometry(\"POLYGON\", srid=4326)}) # type: ignore\n",
    "print(\"Donn√©es des zones NYC import√©es dans PostgreSQL !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 4 : Chargement et conversion des coordonn√©es GPS en CSV\n",
    "csv_path = \"data_clean/points_taxis.csv\"\n",
    "\n",
    "data_cleaned['geometry_pickup'] = gpd.points_from_xy(data_cleaned['pickup_longitude'], data_cleaned['pickup_latitude'])\n",
    "data_cleaned['geometry_dropoff'] = gpd.points_from_xy(data_cleaned['dropoff_longitude'], data_cleaned['dropoff_latitude'])\n",
    "\n",
    "data_cleaned[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']].to_csv(csv_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Donn√©es GPS enregistr√©es en CSV pour `pickup` et `dropoff` \")\n",
    "\n",
    "\n",
    "print(\"Donn√©es GPS sauvegard√©es en CSV pour import rapide \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 5 : Suppression des index pour acc√©l√©rer l'insertion\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"DROP INDEX IF EXISTS idx_points_geo;\"))\n",
    "    conn.execute(text(\"DROP INDEX IF EXISTS idx_zones_geo;\"))\n",
    "    print(\"Index supprim√©s temporairement pour acc√©l√©rer l'insertion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 6 : Cr√©ation de la table `points_taxis`\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        DROP TABLE IF EXISTS points_taxis;\n",
    "        CREATE TABLE points_taxis (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            pickup_longitude DOUBLE PRECISION,\n",
    "            pickup_latitude DOUBLE PRECISION,\n",
    "            dropoff_longitude DOUBLE PRECISION,\n",
    "            dropoff_latitude DOUBLE PRECISION,\n",
    "            geometry_pickup GEOMETRY(Point, 4326),\n",
    "            geometry_dropoff GEOMETRY(Point, 4326)\n",
    "        );\n",
    "    \"\"\"))\n",
    "    print(\"Table `points_taxis` cr√©√©e !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 7 : Importer les donn√©es GPS via `COPY` (ultra-rapide)\n",
    "conn = engine.raw_connection()  # Ouvrir la connexion\n",
    "cursor = conn.cursor()\n",
    "\n",
    "try:\n",
    "    with open(csv_path, \"r\") as f:\n",
    "        cursor.copy_expert(\"COPY points_taxis(pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude) FROM STDIN WITH CSV HEADER DELIMITER ',';\", f)\n",
    "    conn.commit()\n",
    "    print(\"Donn√©es des taxis import√©es via `COPY` üöÄ\")\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 8 : Ajouter les colonnes `geometry_pickup` et `geometry_dropoff`\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        UPDATE points_taxis\n",
    "        SET geometry_pickup = ST_SetSRID(ST_MakePoint(pickup_longitude, pickup_latitude), 4326),\n",
    "            geometry_dropoff = ST_SetSRID(ST_MakePoint(dropoff_longitude, dropoff_latitude), 4326);\n",
    "    \"\"\"))\n",
    "    print(\"G√©om√©tries `pickup` et `dropoff` ajout√©es !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  √âtape 9 : R√©activation des index\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"CREATE INDEX IF NOT EXISTS idx_points_geo ON points_taxis USING GIST (geometry_pickup);\"))\n",
    "    conn.execute(text(\"CREATE INDEX IF NOT EXISTS idx_points_dropoff ON points_taxis USING GIST (geometry_dropoff);\"))\n",
    "    conn.execute(text(\"CREATE INDEX IF NOT EXISTS idx_zones_geo ON zones_nyc USING GIST (geometry);\"))\n",
    "print(\"Index recr√©√©s apr√®s insertion !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 10 : Jointure spatiale optimis√©e pour `pickup` et `dropoff`\n",
    "query = \"\"\"\n",
    "SELECT  p.*, \n",
    "        z_pickup.borough AS pickup_borough, \n",
    "        z_pickup.neighborhood AS pickup_neighborhood,\n",
    "        z_dropoff.borough AS dropoff_borough,\n",
    "        z_dropoff.neighborhood AS dropoff_neighborhood\n",
    "FROM points_taxis p\n",
    "LEFT JOIN zones_nyc z_pickup ON ST_Within(p.geometry_pickup, z_pickup.geometry)\n",
    "LEFT JOIN zones_nyc z_dropoff ON ST_Within(p.geometry_dropoff, z_dropoff.geometry);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PostGIS est actif, version : 3.5 USE_GEOS=1 USE_PROJ=1 USE_STATS=1\n",
      "‚úÖ PostGIS est bien activ√©, version : 3.5 USE_GEOS=1 USE_PROJ=1 USE_STATS=1\n",
      "üìå Colonnes du GeoJSON : Index(['neighborhood', 'boroughCode', 'borough', 'X.id', 'geometry'], dtype='object')\n",
      "‚úÖ Donn√©es des zones NYC import√©es dans PostgreSQL !\n",
      "‚úÖ Donn√©es GPS enregistr√©es en CSV pour `pickup` et `dropoff` üöÄ\n",
      "‚úÖ Donn√©es GPS sauvegard√©es en CSV pour import rapide üöÄ\n",
      "üöÄ Index supprim√©s temporairement pour acc√©l√©rer l'insertion\n",
      "‚úÖ Table `points_taxis` cr√©√©e !\n",
      "‚úÖ Donn√©es des taxis import√©es via `COPY` üöÄ\n",
      "‚úÖ G√©om√©tries `pickup` et `dropoff` ajout√©es !\n",
      "‚úÖ Index recr√©√©s apr√®s insertion !\n",
      "‚úÖ Jointure termin√©e avec `pickup` et `dropoff` !\n",
      "   pickup_latitude  pickup_longitude pickup_borough  dropoff_latitude  \\\n",
      "0        40.734695        -73.990372      Manhattan         40.732407   \n",
      "1        40.729912        -73.980782      Manhattan         40.716679   \n",
      "2        40.679565        -73.984550       Brooklyn         40.788925   \n",
      "3        40.718990        -73.993469      Manhattan         40.657333   \n",
      "4        40.781330        -73.960625      Manhattan         40.758514   \n",
      "\n",
      "   dropoff_longitude dropoff_borough pickup_neighborhood  \\\n",
      "0         -73.981842       Manhattan            Gramercy   \n",
      "1         -73.944473        Brooklyn        East Village   \n",
      "2         -73.950272       Manhattan             Gowanus   \n",
      "3         -73.962242        Brooklyn     Lower East Side   \n",
      "4         -73.977264       Manhattan        Central Park   \n",
      "\n",
      "        dropoff_neighborhood  \n",
      "0                   Gramercy  \n",
      "1               Williamsburg  \n",
      "2                East Harlem  \n",
      "3  Prospect-Lefferts Gardens  \n",
      "4                    Midtown  \n"
     ]
    }
   ],
   "source": [
    "# √âtape 11 : R√©cup√©rer les r√©sultats et ajouter aux donn√©es\n",
    "result = pd.read_sql(query, engine)\n",
    "data_cleaned['pickup_borough'] = result['pickup_borough']\n",
    "data_cleaned['pickup_neighborhood'] = result['pickup_neighborhood']\n",
    "data_cleaned['dropoff_borough'] = result['dropoff_borough']\n",
    "data_cleaned['dropoff_neighborhood'] = result['dropoff_neighborhood']\n",
    "\n",
    "print(\"Jointure termin√©e avec `pickup` et `dropoff` !\")\n",
    "print(data_cleaned[['pickup_latitude', 'pickup_longitude', 'pickup_borough', 'dropoff_latitude', 'dropoff_longitude', 'dropoff_borough', 'pickup_neighborhood', 'dropoff_neighborhood']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.drop(columns=['geometry_pickup', 'geometry_dropoff'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Enregistrelment en format parquert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier enregistr√© en Parquet avec succ√®s ! üöÄ\n"
     ]
    }
   ],
   "source": [
    "data_cleaned.to_parquet('data_clean/taxi_trip_2016-preclean.parquet', index=False)\n",
    "print(\"Fichier enregistr√© en Parquet avec succ√®s !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
