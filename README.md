# NYC Taxi Services - Data Processing & Visualization  

## ğŸŒŸ Contexte et PrÃ©sentation  
Ce projet sâ€™appuie sur un **jeu de donnÃ©es public** issu de **Kaggle**, contenant des informations dÃ©taillÃ©es sur les trajets effectuÃ©s par les taxis de New York. Lâ€™objectif est dâ€™explorer et dâ€™analyser ces donnÃ©es afin de mieux comprendre les tendances des dÃ©placements, dâ€™identifier les Ã©ventuelles anomalies et dâ€™optimiser leur exploitation pour des analyses plus poussÃ©es.  

GrÃ¢ce Ã  un **pipeline de traitement des donnÃ©es**, nous effectuons diffÃ©rentes Ã©tapes : **nettoyage, transformation, stockage et visualisation** des donnÃ©es. Ce projet met en avant des techniques de manipulation de donnÃ©es en **Python (Pandas, NumPy, etc.)**, dâ€™optimisation des performances via **PostgreSQL**, et de crÃ©ation de visualisations interactives avec **Power BI**.

---

## ğŸ¯ Objectif du Projet  
Ce projet a pour but d'effectuer un traitement approfondi des donnÃ©es de NYC Taxi Services afin de :  
âœ… Nettoyer et structurer les donnÃ©es pour une meilleure analyse.  
âœ… Identifier et traiter les valeurs aberrantes.  
âœ… Optimiser le stockage et la rapiditÃ© dâ€™accÃ¨s aux donnÃ©es.  
âœ… Visualiser les tendances et insights clÃ©s sur **Power BI**.  

---

## ğŸ“‚ Source des DonnÃ©es  
Les donnÃ©es utilisÃ©es dans ce projet proviennent de **Kaggle**. Vous pouvez les tÃ©lÃ©charger en suivant ce lien :  

ğŸ”— **[NYC Taxi Dataset - Kaggle](https://www.kaggle.com/datasets/elemento/nyc-yellow-taxi-trip-data)** 

Une fois tÃ©lÃ©chargÃ©es, placez les fichiers dans le dossier **`data_brut/`** du projet.

---

## ğŸ—ƒï¸ Structure du Projet  
```plaintext
nyc_taxi_project/
â”œâ”€â”€  data_geojson/ 
â”œâ”€â”€  data_brut/ 
â”œâ”€â”€  data_clean/                         # Contient les fichiers de donnÃ©es (Ã  tÃ©lÃ©charger depuis Kaggle)
â”œâ”€â”€  notebooks/                          # Notebooks Jupyter pour lâ€™analyse et le traitement des donnÃ©es
â”‚   â”œâ”€â”€ cleaning_step.ipynb              # Nettoyage et prÃ©paration des donnÃ©es
â”‚   â”œâ”€â”€ convert_parquet.ipynb            # Conversion des fichiers en format Parquet
â”‚   â””â”€â”€ outliers_identification.ipynb    # Identification et gestion des valeurs aberrantes
â”œâ”€â”€  sql/                                # Contient les scripts SQL
â”‚   â””â”€â”€ sql.sql                          # RequÃªtes SQL pour le traitement des donnÃ©es
â”œâ”€â”€  powerbi/                            # Contient le rapport Power BI
â”‚   â””â”€â”€ nyc_taxi_report.pbix             # Fichier Power BI (format .pbix)
â”œâ”€â”€  .env                                # Fichier contenant les variables environnement
â”œâ”€â”€  requirements.txt                    # Liste des dÃ©pendances Python
â””â”€â”€  README.md                           # Documentation du projet
```

---

## ğŸ› ï¸ Contenu du Projet  

### 1ï¸âƒ£ PrÃ©traitement des DonnÃ©es  
Les diffÃ©rentes Ã©tapes de prÃ©paration et de transformation des donnÃ©es sont rÃ©alisÃ©es via des **notebooks Jupyter** :  
ğŸ“Œ **`convert_parquet.ipynb`** : Ajout des informations du geojson et conversion des fichiers en **Parquet** pour un stockage optimisÃ©.  
ğŸ“Œ **`cleaning_step.ipynb`** : Nettoyage et structuration des donnÃ©es.  
ğŸ“Œ **`outliers_identification.ipynb`** : DÃ©tection et gestion des **valeurs illogiques** et des **outliers de distance et temps de course**.  

### 2ï¸âƒ£ Traitement SQL  
Le fichier **`sql.sql`** contient les **requÃªtes SQL** exÃ©cutÃ©es sous **PostgreSQL** pour l'agrÃ©gation et lâ€™optimisation des donnÃ©es issuent du geojson.

### 3ï¸âƒ£ Visualisation des DonnÃ©es  
Les **donnÃ©es traitÃ©es** sont exploitÃ©es pour fournir des **visualisations interactives sur Power BI**.  
ğŸ”— **AccÃ©dez au tableau de bord Power BI** :  
[![Power BI](https://img.shields.io/badge/Power_BI-Dashboard-orange?logo=powerbi)](https://app.powerbi.com/view?r=eyJrIjoiYjA2NWNiNTktM2Q1YS00YWE4LWI5OGUtMTBlY2VkNTdmYjA3IiwidCI6IjQ0OTFmMGVlLWY1MDMtNDcyNi1hNWViLTFmMGM0ZGFjODJhOSJ9&pageName=0ddccbb621013b0fcf8d)  

---

## ğŸ’ª PrÃ©requis  
Pour exÃ©cuter ce projet, vous aurez besoin des outils suivants :  
- **Python 3.12**  
- **Jupyter Notebook**  
- **PostgreSQL**  
- **Power BI Desktop**  

---

## ğŸ›  Installation  
1ï¸âƒ£ **Clonez le dÃ©pÃ´t** :  
```sh
git clone https://github.com/ton-repo.git
cd ton-repo
```
2ï¸âƒ£ **Installez les dÃ©pendances** :  
```sh
pip install -r requirements.txt
```
3ï¸âƒ£ **TÃ©lÃ©chargez les donnÃ©es depuis Kaggle** et placez-les dans le dossier `data/`.  

4ï¸âƒ£ **Mettre en place le fichier .env
CrÃ©ez un fichier .env Ã  la racine avec le contenu suivant :
```ini
DB_NAME=nyc_geo
DB_USER=postgres
DB_PASSWORD=[Password]
DB_HOST=localhost
DB_PORT=5432
```
Remplacez [Password] par votre valeur rÃ©elle.

5ï¸âƒ£ **Lancez Jupyter Notebook** et exÃ©cutez les notebooks dans lâ€™ordre recommandÃ©.  

---

## ğŸ“© Contact  
Pour toute question ou suggestion, nâ€™hÃ©sitez pas Ã  ouvrir une **issue** ou Ã  me contacter directement.  

ğŸ“§ Email : contact@datadriven-dynamix.fr  
ğŸŒ LinkedIn : www.linkedin.com/in/dim-lefebvre60 

---

## ğŸ“š Licence
Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

